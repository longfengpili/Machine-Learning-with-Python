{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2d. Distributed training and monitoring </h1>\n",
    "\n",
    "In this notebook, we refactor to call ```train_and_evaluate``` instead of hand-coding our ML pipeline. This allows us to carry out evaluation as part of our training loop instead of as a separate step. It also adds in failure-handling that is necessary for distributed training capabilities.\n",
    "\n",
    "We also use TensorBoard to monitor the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:17:27.377651Z",
     "start_time": "2019-06-17T03:17:22.071719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery as bq\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Input </h2>\n",
    "\n",
    "Read data created in Lab1a, but this time make it more general, so that we are reading in batches.  Instead of using Pandas, we will use Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:34:39.006538Z",
     "start_time": "2019-06-17T03:34:38.999530Z"
    }
   },
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['fare_amount', 'pickuplon', 'pickuplat',\n",
    "               'dropofflon', 'dropofflat', 'passengers' ,'key']\n",
    "LABEL_COLUMN = 'fare_amount'\n",
    "DEFAULTS = [[0.0], [-74.0], [40.0], [-74.0], [40.7], [1.0], ['nokey']]\n",
    "\n",
    "\n",
    "def read_dataset(filename, mode, batch_size=512):\n",
    "    def _input_fn():\n",
    "        def decode_csv(value_column):\n",
    "            columns = tf.decode_csv(value_column, record_defaults=DEFAULTS)\n",
    "            features = dict(zip(CSV_COLUMNS, columns))\n",
    "            label = features.pop(LABEL_COLUMN)\n",
    "            return features, label\n",
    "\n",
    "        # Create list of files that match pattern\n",
    "        file_list = tf.gfile.Glob(filename)\n",
    "\n",
    "        # Create dataset from file list\n",
    "        dataset = tf.data.TextLineDataset(file_list).map(decode_csv)\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None  # indefinitely\n",
    "            dataset = dataset.shuffle(buffer_size=10 * batch_size)\n",
    "        else:\n",
    "            num_epochs = 1  # end-of-input after this\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:34:39.506566Z",
     "start_time": "2019-06-17T03:34:39.503600Z"
    }
   },
   "outputs": [],
   "source": [
    "train_t = read_dataset('e:/data/create_datasets/taxi-train.csv',mode=tf.estimator.ModeKeys.TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create features out of input data </h2>\n",
    "\n",
    "For now, pass these through.  (same as previous lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:34:40.852824Z",
     "start_time": "2019-06-17T03:34:40.848866Z"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = [\n",
    "    tf.feature_column.numeric_column('pickuplon'),\n",
    "    tf.feature_column.numeric_column('pickuplat'),\n",
    "    tf.feature_column.numeric_column('dropofflat'),\n",
    "    tf.feature_column.numeric_column('dropofflon'),\n",
    "    tf.feature_column.numeric_column('passengers'),\n",
    "]\n",
    "\n",
    "def add_more_features(feats):\n",
    "  # Nothing to add (yet!)\n",
    "  return feats\n",
    "\n",
    "feature_cols = add_more_features(INPUT_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> train_and_evaluate </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:34:42.100483Z",
     "start_time": "2019-06-17T03:34:42.095497Z"
    }
   },
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    feature_placeholders = {\n",
    "        'pickuplon': tf.placeholder(tf.float32, [None]),\n",
    "        'pickuplat': tf.placeholder(tf.float32, [None]),\n",
    "        'dropofflat': tf.placeholder(tf.float32, [None]),\n",
    "        'dropofflon': tf.placeholder(tf.float32, [None]),\n",
    "        'passengers': tf.placeholder(tf.float32, [None]),\n",
    "    }\n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in feature_placeholders.items()\n",
    "    }\n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:34:42.900506Z",
     "start_time": "2019-06-17T03:34:42.895519Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "    estimator = tf.estimator.LinearRegressor(\n",
    "        model_dir=output_dir,\n",
    "        feature_columns=feature_cols)\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=read_dataset('e:/data/create_datasets/taxi-train.csv',\n",
    "                              mode=tf.estimator.ModeKeys.TRAIN),\n",
    "        max_steps=num_train_steps)\n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn=read_dataset('e:/data/create_datasets/taxi-valid.csv',\n",
    "                              mode=tf.estimator.ModeKeys.EVAL),\n",
    "        steps=None,\n",
    "        start_delay_secs=1,  # start evaluating after N seconds\n",
    "        throttle_secs=10,  # evaluate every N seconds\n",
    "        exporters=exporter)\n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-17T03:36:04.038942Z",
     "start_time": "2019-06-17T03:34:43.514575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'taxi_trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000200F98A15C0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into taxi_trained\\model.ckpt.\n",
      "INFO:tensorflow:loss = 100841.33, step = 1\n",
      "INFO:tensorflow:global_step/sec: 59.5412\n",
      "INFO:tensorflow:loss = 40708.305, step = 101 (1.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.5342\n",
      "INFO:tensorflow:loss = 35275.484, step = 201 (1.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.3634\n",
      "INFO:tensorflow:loss = 36290.707, step = 301 (1.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.8646\n",
      "INFO:tensorflow:loss = 43851.254, step = 401 (1.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.1831\n",
      "INFO:tensorflow:loss = 47264.82, step = 501 (1.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.5771\n",
      "INFO:tensorflow:loss = 36668.53, step = 601 (1.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.406\n",
      "INFO:tensorflow:loss = 77606.36, step = 701 (1.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.94\n",
      "INFO:tensorflow:loss = 31164.582, step = 801 (1.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.406\n",
      "INFO:tensorflow:loss = 64516.84, step = 901 (1.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.5637\n",
      "INFO:tensorflow:loss = 38398.207, step = 1001 (1.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.1583\n",
      "INFO:tensorflow:loss = 36710.082, step = 1101 (1.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.845\n",
      "INFO:tensorflow:loss = 35356.863, step = 1201 (1.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.2782\n",
      "INFO:tensorflow:loss = 46991.953, step = 1301 (1.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.7063\n",
      "INFO:tensorflow:loss = 46701.344, step = 1401 (1.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.0242\n",
      "INFO:tensorflow:loss = 52352.96, step = 1501 (1.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.2783\n",
      "INFO:tensorflow:loss = 52646.258, step = 1601 (1.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.9821\n",
      "INFO:tensorflow:loss = 42880.273, step = 1701 (1.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.8239\n",
      "INFO:tensorflow:loss = 58001.055, step = 1801 (1.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.151\n",
      "INFO:tensorflow:loss = 33524.5, step = 1901 (1.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.0665\n",
      "INFO:tensorflow:loss = 44327.35, step = 2001 (1.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.2268\n",
      "INFO:tensorflow:loss = 67744.28, step = 2101 (1.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.7304\n",
      "INFO:tensorflow:loss = 61902.508, step = 2201 (1.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.1831\n",
      "INFO:tensorflow:loss = 83247.23, step = 2301 (1.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.706\n",
      "INFO:tensorflow:loss = 44077.508, step = 2401 (1.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.6469\n",
      "INFO:tensorflow:loss = 47341.734, step = 2501 (1.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.9654\n",
      "INFO:tensorflow:loss = 46878.098, step = 2601 (1.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.8355\n",
      "INFO:tensorflow:loss = 44176.742, step = 2701 (1.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.7023\n",
      "INFO:tensorflow:loss = 37867.25, step = 2801 (1.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.6887\n",
      "INFO:tensorflow:loss = 46313.465, step = 2901 (1.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.4022\n",
      "INFO:tensorflow:loss = 51802.195, step = 3001 (1.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.151\n",
      "INFO:tensorflow:loss = 76484.24, step = 3101 (1.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.406\n",
      "INFO:tensorflow:loss = 37351.4, step = 3201 (1.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.856\n",
      "INFO:tensorflow:loss = 54153.766, step = 3301 (1.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.3152\n",
      "INFO:tensorflow:loss = 41314.04, step = 3401 (1.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.3634\n",
      "INFO:tensorflow:loss = 40772.79, step = 3501 (1.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.8141\n",
      "INFO:tensorflow:loss = 47218.516, step = 3601 (1.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.8141\n",
      "INFO:tensorflow:loss = 67477.56, step = 3701 (1.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.3633\n",
      "INFO:tensorflow:loss = 45785.82, step = 3801 (1.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.4022\n",
      "INFO:tensorflow:loss = 40097.92, step = 3901 (1.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.7304\n",
      "INFO:tensorflow:loss = 46482.83, step = 4001 (1.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.4487\n",
      "INFO:tensorflow:loss = 43468.074, step = 4101 (1.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.0686\n",
      "INFO:tensorflow:loss = 46629.33, step = 4201 (1.561 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.5221\n",
      "INFO:tensorflow:loss = 46895.44, step = 4301 (1.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.274\n",
      "INFO:tensorflow:loss = 65268.273, step = 4401 (1.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.94\n",
      "INFO:tensorflow:loss = 59540.227, step = 4501 (1.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.2602\n",
      "INFO:tensorflow:loss = 43739.344, step = 4601 (1.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.1933\n",
      "INFO:tensorflow:loss = 55564.133, step = 4701 (1.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.0243\n",
      "INFO:tensorflow:loss = 40703.977, step = 4801 (1.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.3401\n",
      "INFO:tensorflow:loss = 58354.758, step = 4901 (1.579 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into taxi_trained\\model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-17T03:36:02Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\normal\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-17-03:36:03\n",
      "INFO:tensorflow:Saving dict for global step 5000: average_loss = 89.67217, global_step = 5000, label/mean = 11.44928, loss = 35218.746, prediction/mean = 11.88305\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: taxi_trained\\model.ckpt-5000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\envs\\normal\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'pickuplon': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'pickuplat': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'dropofflat': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'dropofflon': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'passengers': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'pickuplon': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=float32>, 'pickuplat': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=float32>, 'dropofflat': <tf.Tensor 'Placeholder_2:0' shape=(?,) dtype=float32>, 'dropofflon': <tf.Tensor 'Placeholder_3:0' shape=(?,) dtype=float32>, 'passengers': <tf.Tensor 'Placeholder_4:0' shape=(?,) dtype=float32>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained\\model.ckpt-5000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: taxi_trained\\export\\exporter\\temp-b'1560742563'\\saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 53343.93.\n"
     ]
    }
   ],
   "source": [
    "# Run training    \n",
    "OUTDIR = 'taxi_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "train_and_evaluate(OUTDIR, num_train_steps = 5000)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
